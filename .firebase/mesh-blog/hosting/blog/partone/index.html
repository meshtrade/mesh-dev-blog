<!DOCTYPE html><html lang="en" data-astro-cid-bvzihdzo> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v4.16.4"><!-- Font preloads --><link rel="preload" href="/fonts/atkinson-regular.woff" as="font" type="font/woff" crossorigin><link rel="preload" href="/fonts/atkinson-bold.woff" as="font" type="font/woff" crossorigin><!-- Canonical URL --><link rel="canonical" href="https://example.com/blog/partone/"><!-- Primary Meta Tags --><title>AI Visualised - Part I</title><meta name="title" content="AI Visualised - Part I"><meta name="description" content="Looking at how we can build an intuition for neural networks visually"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://example.com/blog/partone/"><meta property="og:title" content="AI Visualised - Part I"><meta property="og:description" content="Looking at how we can build an intuition for neural networks visually"><meta property="og:image" content="https://example.com/blog-placeholder-1.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://example.com/blog/partone/"><meta property="twitter:title" content="AI Visualised - Part I"><meta property="twitter:description" content="Looking at how we can build an intuition for neural networks visually"><meta property="twitter:image" content="https://example.com/blog-placeholder-1.jpg"><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><link rel="stylesheet" href="/_astro/_slug_.TC8mnIAJ.css">
<style>main[data-astro-cid-bvzihdzo]{width:calc(100% - 2em);max-width:100%;margin:0}.hero-image[data-astro-cid-bvzihdzo]{width:100%}.hero-image[data-astro-cid-bvzihdzo] img[data-astro-cid-bvzihdzo]{display:block;margin:0 auto;border-radius:12px;box-shadow:var(--box-shadow)}.prose[data-astro-cid-bvzihdzo]{width:720px;max-width:calc(100% - 2em);margin:auto;padding:1em;color:rgb(var(--gray-dark))}.title[data-astro-cid-bvzihdzo]{margin-bottom:1em;padding:1em 0;text-align:center;line-height:1}.title[data-astro-cid-bvzihdzo] h1[data-astro-cid-bvzihdzo]{margin:0 0 .5em}.date[data-astro-cid-bvzihdzo]{margin-bottom:.5em;color:rgb(var(--gray))}.author[data-astro-cid-bvzihdzo]{margin-bottom:.5em;color:rgb(var(--gray));font-size:medium;font-style:italic}.last-updated-on[data-astro-cid-bvzihdzo]{font-style:italic}article[data-astro-cid-bvzihdzo] a[data-astro-cid-bvzihdzo]:before{content:""}article[data-astro-cid-bvzihdzo] a[data-astro-cid-bvzihdzo]:before,article[data-astro-cid-bvzihdzo] a[data-astro-cid-bvzihdzo]:after{position:absolute;width:100%;height:1px;background:linear-gradient(to right,#c500cf,#dc0451);top:100%;left:0;pointer-events:none;transform-origin:100% 50%;transform:scale3d(0,1,1);transition:transform .3s}article[data-astro-cid-bvzihdzo] a[data-astro-cid-bvzihdzo]:hover:before{transform-origin:0% 50%;transform:scaleZ(1)}
</style><script type="module" src="/_astro/hoisted.2daoxv0f.js"></script><style>.done-container[data-astro-cid-nip4t23h]{display:flex;align-items:center;justify-content:center;border-radius:12px;position:relative;height:100px;max-height:100px}.star[data-astro-cid-nip4t23h]{position:absolute;top:-50px;background:gray;border-radius:50%;box-shadow:0 0 0 4px #ffffff1a,0 0 0 8px #ffffff1a,0 0 20px #ff00001a;animation:animate 6s linear infinite}.star[data-astro-cid-nip4t23h]:before{content:"";position:absolute;top:0;transform:translateY(-50%);width:300px;height:1px;background:linear-gradient(90deg,rgba(255,21,91),blue,transparent)}@keyframes animate{0%{transform:rotate(315deg) translate(0);opacity:1}70%{opacity:1}to{transform:rotate(315deg) translate(-1000px);opacity:0}}.star[data-astro-cid-nip4t23h]:nth-child(1){top:-300px;left:initial;animation-delay:0s;animation-duration:6s}.star[data-astro-cid-nip4t23h]:nth-child(2){top:-30px;right:-10px;left:initial;animation-delay:.2s;animation-duration:5s}.star[data-astro-cid-nip4t23h]:nth-child(3){top:-30px;right:350px;left:initial;animation-delay:.4s;animation-duration:4s}
</style><style>.plot[data-astro-cid-6ryhialg]{background:radial-gradient(circle at 100% 100%,#ffffff 0,#ffffff 3px,transparent 3px) 0% 0%/8px 8px no-repeat,radial-gradient(circle at 0 100%,#ffffff 0,#ffffff 3px,transparent 3px) 100% 0%/8px 8px no-repeat,radial-gradient(circle at 100% 0,#ffffff 0,#ffffff 3px,transparent 3px) 0% 100%/8px 8px no-repeat,radial-gradient(circle at 0 0,#ffffff 0,#ffffff 3px,transparent 3px) 100% 100%/8px 8px no-repeat,linear-gradient(#fff,#fff) 50% 50%/ calc(100% - 10px) calc(100% - 16px) no-repeat,linear-gradient(#fff,#fff) 50% 50%/ calc(100% - 16px) calc(100% - 10px) no-repeat,linear-gradient(8deg,rgba(249,7,16,.59) 0%,transparent 29.163%,rgba(225,50,44,.97) 70.558%,rgba(243,12,31,.23) 80.976%,#f3a60a 100%),linear-gradient(97deg,#f01c3b,#e51184 12.972%,#ee29ba 96.764%,#e6309e);border-radius:8px;padding:9px;box-sizing:border-box}.refresh-btn[data-astro-cid-6ryhialg]{opacity:1;background-color:transparent;border:none;cursor:pointer}.refresh-btn[data-astro-cid-6ryhialg]:hover{-webkit-animation:rotate-center 1s both;animation:rotate-center 1s both}@media (max-width: 720px){.plot[data-astro-cid-6ryhialg]:before{content:"Plots not supported on mobile";height:50px}.plot-iframe[data-astro-cid-6ryhialg],.refresh-btn[data-astro-cid-6ryhialg]{display:none}}@-webkit-keyframes rotate-center{0%{-webkit-transform:rotate(0);transform:rotate(0)}to{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes rotate-center{0%{-webkit-transform:rotate(0);transform:rotate(0)}to{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}
</style><style>.scroll-container[data-astro-cid-yiedy3cl]{width:80px;height:80px;position:fixed;bottom:40px;right:25px;transform:rotate(180deg);display:none;z-index:99}.scroll-container[data-astro-cid-yiedy3cl]:hover .scroll[data-astro-cid-yiedy3cl]{border:2px solid white;cursor:pointer;animation:none}.scroll[data-astro-cid-yiedy3cl]{width:60px;height:60px;border:2px solid #333;border-radius:50%;position:relative;transition:all;transition-duration:.2s;animation:down 1.5s normal;-webkit-animation:down 1.5s normal}.scroll[data-astro-cid-yiedy3cl]:before{content:"";position:absolute;top:15px;left:20px;width:18px;height:18px;border-left-width:2px;border-left-style:solid;border-image:linear-gradient(to right,#c500cf 50%,#dc0451) 1;border-bottom:2px solid #333;transform:rotate(-45deg)}@-webkit-keyframes down{0%{transform:translate(0)}20%{transform:translateY(15px)}40%{transform:translate(0)}}
</style><script src="/_astro/Scroll.astro_astro_type_script_index_0_lang.l0sNRNKZ.js" type="module"></script><style>[data-astro-transition-scope="astro-piznz4bv-1"] { view-transition-name: AI_20Visualised_20-_20Part_20I_20image; }@layer astro { ::view-transition-old(AI_20Visualised_20-_20Part_20I_20image) { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeOut; }::view-transition-new(AI_20Visualised_20-_20Part_20I_20image) { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeIn; }[data-astro-transition=back]::view-transition-old(AI_20Visualised_20-_20Part_20I_20image) { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeOut; }[data-astro-transition=back]::view-transition-new(AI_20Visualised_20-_20Part_20I_20image) { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeIn; } }[data-astro-transition-fallback="old"] [data-astro-transition-scope="astro-piznz4bv-1"],
			[data-astro-transition-fallback="old"][data-astro-transition-scope="astro-piznz4bv-1"] { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeOut; }[data-astro-transition-fallback="new"] [data-astro-transition-scope="astro-piznz4bv-1"],
			[data-astro-transition-fallback="new"][data-astro-transition-scope="astro-piznz4bv-1"] { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeIn; }[data-astro-transition=back][data-astro-transition-fallback="old"] [data-astro-transition-scope="astro-piznz4bv-1"],
			[data-astro-transition=back][data-astro-transition-fallback="old"][data-astro-transition-scope="astro-piznz4bv-1"] { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeOut; }[data-astro-transition=back][data-astro-transition-fallback="new"] [data-astro-transition-scope="astro-piznz4bv-1"],
			[data-astro-transition=back][data-astro-transition-fallback="new"][data-astro-transition-scope="astro-piznz4bv-1"] { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeIn; }</style><style>[data-astro-transition-scope="astro-eiglh4mu-2"] { view-transition-name: AI_20Visualised_20-_20Part_20I_20title; }@layer astro { ::view-transition-old(AI_20Visualised_20-_20Part_20I_20title) { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeOut; }::view-transition-new(AI_20Visualised_20-_20Part_20I_20title) { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeIn; }[data-astro-transition=back]::view-transition-old(AI_20Visualised_20-_20Part_20I_20title) { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeOut; }[data-astro-transition=back]::view-transition-new(AI_20Visualised_20-_20Part_20I_20title) { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeIn; } }[data-astro-transition-fallback="old"] [data-astro-transition-scope="astro-eiglh4mu-2"],
			[data-astro-transition-fallback="old"][data-astro-transition-scope="astro-eiglh4mu-2"] { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeOut; }[data-astro-transition-fallback="new"] [data-astro-transition-scope="astro-eiglh4mu-2"],
			[data-astro-transition-fallback="new"][data-astro-transition-scope="astro-eiglh4mu-2"] { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeIn; }[data-astro-transition=back][data-astro-transition-fallback="old"] [data-astro-transition-scope="astro-eiglh4mu-2"],
			[data-astro-transition=back][data-astro-transition-fallback="old"][data-astro-transition-scope="astro-eiglh4mu-2"] { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeOut; }[data-astro-transition=back][data-astro-transition-fallback="new"] [data-astro-transition-scope="astro-eiglh4mu-2"],
			[data-astro-transition=back][data-astro-transition-fallback="new"][data-astro-transition-scope="astro-eiglh4mu-2"] { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeIn; }</style></head> <body data-astro-cid-bvzihdzo> <header data-astro-cid-3ef6ksr2> <nav data-astro-cid-3ef6ksr2> <a href="/" class="link" data-astro-cid-eimmu3lg> <div class="mesh-logo"> <svg width="60" height="60" viewBox="0 0 1272 1197" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M908.083 598.043L878.363 609.55L867.354 638.955L925.205 697.066L751.853 871.199L677.105 796.114L735.278 737.679C740.223 741.199 746.038 742.971 751.853 742.971C759.233 742.971 766.589 740.15 772.23 734.484L867.354 638.93L861.813 622.605L826.626 598.018L751.878 673.103L675.639 596.52L636.376 638.93L602.829 590.779L520.875 673.103L441.654 593.525L405.398 638.93L500.523 734.484C506.139 740.125 513.519 742.971 520.9 742.971C526.715 742.971 532.505 741.174 537.475 737.679L595.648 796.114L520.9 871.199L347.523 697.066L405.373 638.955L371.851 590.779L286.443 676.623C275.186 687.93 275.186 706.252 286.443 717.535L500.523 932.58C506.139 938.222 513.519 941.067 520.9 941.067C528.28 941.067 535.636 938.247 541.277 932.58L636.401 837.027L731.526 932.58C737.142 938.222 744.522 941.067 751.903 941.067C759.283 941.067 766.639 938.247 772.279 932.58L986.36 717.535C997.617 706.227 997.617 687.905 986.36 676.623L908.133 598.043H908.083ZM578.501 697.091L636.352 638.98L694.202 697.091L636.352 755.202L578.501 697.091Z" fill="#403B65"></path> <path d="M347.523 498.995L520.9 324.862L595.648 399.947L536.133 459.73C537.45 460.679 538.742 461.702 539.935 462.9L577.184 500.318L636.376 440.859L696.513 501.266L733.762 463.849C734.955 462.65 736.223 461.627 737.564 460.678L677.13 399.972L751.878 324.887L925.229 499.02L867.379 557.131L880.848 583.191L908.108 598.068L986.335 519.488C997.592 508.181 997.592 489.859 986.335 478.576L772.205 263.481C760.948 252.173 742.708 252.173 731.476 263.481L636.352 359.034L541.252 263.481C529.995 252.173 511.755 252.173 500.523 263.481L286.443 478.551C275.186 489.859 275.186 508.181 286.443 519.463L364.67 598.043L409.797 561.549L347.548 499.02L347.523 498.995Z" fill="#403B65"></path> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M446.104 598.032L405.374 638.947L429.675 663.357L470.406 622.443L446.104 598.032Z" fill="#403B65"></path> </g> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M660.58 663.293L701.309 622.356L679.043 599.99L677.055 598.043L636.376 638.98L637.147 639.779L660.58 663.293Z" fill="#403B65"></path> </g> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M537.449 737.704L562.1 762.441L602.829 721.529L578.501 697.091L537.449 737.704Z" fill="#403B65"></path> </g> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M677.104 796.137L636.374 837.051L660.71 861.497L701.44 820.583L677.104 796.137Z" fill="#403B65"></path> </g> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M677.082 399.957L636.351 440.871L660.67 465.3L701.4 424.386L677.082 399.957Z" fill="#403B65"></path> </g> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M826.608 598.042L802.289 622.47L843.02 663.385L867.338 638.956L826.608 598.042Z" fill="#403B65"></path> </g> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M694.226 697.091L669.898 721.529L710.627 762.441L735.278 737.704L694.226 697.091Z" fill="#403B65"></path> </g> <path d="M772.205 461.552C762.141 451.443 746.51 450.419 735.278 458.382C733.961 459.331 732.669 460.354 731.476 461.552L636.351 557.131L541.227 461.552C540.034 460.354 538.766 459.331 537.425 458.382C526.193 450.419 510.537 451.443 500.498 461.552L364.645 598.018L405.373 638.93L520.85 522.933L636.326 638.955L751.803 522.908L867.28 638.93L908.008 598.018L772.155 461.552H772.205Z" fill="url(#paint0_linear_2_21)"></path> <defs> <linearGradient id="paint0_linear_2_21" x1="842.679" y1="679.293" x2="605.797" y2="559.24" gradientUnits="userSpaceOnUse"> <stop offset="0.16" stop-color="#403B65"></stop> <stop offset="1" stop-color="#DC0451"></stop> </linearGradient> </defs> </svg> </div> <span class="mask" data-astro-cid-eimmu3lg> <div class="link-container" data-astro-cid-eimmu3lg> <h2 class="link-title1 title" data-astro-cid-eimmu3lg> Mesh.Dev </h2> <h2 class="link-title2 title" data-astro-cid-eimmu3lg>Mesh.Dev</h2> </div> </span> </a>  </nav> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"> </header>  <main data-astro-cid-bvzihdzo> <article data-astro-cid-bvzihdzo> <div class="hero-image" data-astro-cid-bvzihdzo> <img src="/partOne.jpg" alt="" loading="eager" data-astro-cid-bvzihdzo data-astro-transition-scope="astro-piznz4bv-1" width="910" height="510" decoding="async"> </div> <div class="prose" data-astro-cid-bvzihdzo> <div class="title" data-astro-cid-bvzihdzo data-astro-transition-scope="astro-eiglh4mu-2"> <div class="date" data-astro-cid-bvzihdzo> <time datetime="2024-10-16T14:04:48.328Z"> Oct 16, 2024 </time>  </div> <h1 data-astro-cid-bvzihdzo>AI Visualised - Part I</h1> <div class="author" data-astro-cid-bvzihdzo>
Author: <span class="mesh-text" data-astro-cid-bvzihdzo>Kyle Smith</span> </div> </div> <hr data-astro-cid-bvzihdzo>  <div id="AI Visualised - Part I" class="scroll-container" data-astro-cid-yiedy3cl> <div class="scroll" data-astro-cid-yiedy3cl></div>   </div>
<p>The year is 2024 and we have walking-talking robots, we are catching rockets and we have driverless cars. I want us for a moment, to take a step back in time, to the year of 1940 and to the city of Bristol.
Here we will find a neurologist by the name of Dr. William Grey Walter who unknowingly designed one of the earliest forms of what would later be referred to as Artificial Intelligence.
His battery-powered robots were models to test his theory that a minimum number of brain cells can control complex behavior and choice. A rotating photoelectric cell, the machine’s “eye,” scans the horizon continuously until it detects an external light.
Scanning stops and the machine either moves toward the light source or, if the source is too bright, moves away.
He claimed that these robots had the equivalent of two whole neurons and further specaluted that by adding more neurons they would only become more intelligent (spoiler: he was right).</p>
<img src="/images/partOne/tortoise.jpeg" alt="tortoise robot" loading="lazy" width="1020" height="490" decoding="async">
<div align="center"><i>Figure 1: ‘Tortoise’ robot created by Dr. William Grey Walter (<a href="https://www.google.com/url?sa=i&url=https%3A%2F%2Famericanhistory.si.edu%2Fcollections%2Fnmah_879329&psig=AOvVaw2Jn2PCk1YEfYr1HajkeFNU&ust=1729100823888000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCJC4ytX4kIkDFQAAAAAdAAAAABAE">Credit</a>)</i></div>
<p>Now this robot marks the first example of AI and robotics, but this is not the first occurrence of ‘computer learning’ as the robot was purely mechanical, but still captured one of the core tenets of Artificial Intelligence: “cognition is recognition”.
This statement describes that the process of acquiring knowledge and understanding is through the identification of something from a previous encounter.
The argument aligns with how we as humans learn, if we see a dog, we only recognise it as a dog from past experience. Even though this alignment exists we are
still unable to fully reason about how AI systems are able to learn and why they work. However, this does not mean we can not discover insights into how they work.
Now there are two avenues to understanding AI systems, for the mathematical wizards among you, you might reach for a calculus and linear algebra handbook to gain that understanding, but
I want to propose a second avenue, rather than focussing on the complex mathematics that make AI systems tick, we will attempt to build an understanding on top of visualisations
from zooming into the internal components of modern day AI systems. This series will focus on taking an illustrative approach to explaining how different types of neural networks and their respective
algorithms work. It will aim to build this understanding by incrementally introducing the various building blocks of modern day neural networks. This series does not assume any previous
experience or knowledge, it only requires a surface-level understanding of high-school maths and a willingness to learn!</p>
<h3 id="the-perceptron">The Perceptron</h3>
<hr/>
<p>The ‘Tortoise’ robot was a mechanical robot and thus did not follow a computer program, the concept of ‘computer learning’ would remain a mystery until the year of 1957.
This is when Frank Rosenblatt developed the <em>perceptron</em> model, the first model that was able to successfully simulate the human cognitive process at a base level.
His discovery is regarded by most as the match that started the wild fire, that is Artificial Intelligence, that has continued to spread to this day.
The perceptron model (also referred to as a neuron) is still used to today to describe the most simple form of neural network. A perceptron (also called a neuron) is meant to represent a single
biological neuron. In the perceptron model it takes one or more inputs or stimuli and depending on the inputs will ‘activate’ which means it returns a non-zero value.</p>
<img src="/images/partOne/perceptron.png" alt="perceptron model" loading="lazy" width="1020" height="490" decoding="async">
<div align="center"><i>Figure 2: Biological Neuron vs Perceptron Model (<a href="https://www.google.com/url?sa=i&url=https%3A%2F%2Ftowardsdatascience.com%2Fthe-concept-of-artificial-neurons-perceptrons-in-neural-networks-fab22249cbfc&psig=AOvVaw1dFXnPae-DYBkEUfPJuXuo&ust=1729519020353000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCNj-ksiOnYkDFQAAAAAdAAAAABAE">Credit</a>)</i></div>
<p>To get a better intuition for the perceptron model we will use an example scenario, consider the scenario where you want to predict the output of an AND gate.
An AND gate is a digital circuit that is energized when, both of its inputs are energized.
To model this conceptually we say that the circuit will return a value of 1 when both of its inputs are 1 and 0 otherwise.
We summarise the behaviour of the AND gate in the table below:</p>
<div align="center"><img src="/images/partOne/and.png" alt="And Gate"/></div>
<div align="center"><i>Figure 3: And Gate (<a href="https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.build-electronic-circuits.com%2Fand-gate%2F&psig=AOvVaw1X6Qp2SQOJJkVP1JzzFhCl&ust=1729102980864000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCNDxyNqAkYkDFQAAAAAdAAAAABAJ">Credit</a>)</i></div>
<p>A and B are the inputs to the AND gate and Q is the variable representing the output of the AND gate.
If we plot the possible inputs and outputs of the AND gate, we see something interesting emerge.</p>
<div class="plot" data-astro-cid-6ryhialg> <iframe id="plotframe-/html/partOne/and_boundary.html" src="/html/partOne/and_boundary.html" width="100%" height="600px" style="border:none;" title="loss landscape" loading="lazy" class="plot-iframe" data-astro-cid-6ryhialg>
        Data
    </iframe>  </div>  <script>(function(){const htmlPath = "/html/partOne/and_boundary.html";

    if (window !== null) {
        const button = document.getElementById("refreshButton-" + htmlPath);
        if (button) {
            button.addEventListener("click", () => {
                const iframe = document.getElementById("plotframe-"+htmlPath);
                iframe.contentWindow?.location.reload();
            });
        }
    }
  })();</script>
<div align="center"><i>Figure 4: AND Gate Inputs (<a href="">Script</a>)</i></div>
<p>We can clearly separate the points using a single line, where the points below the line mean the AND gate will output <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span> and the point above the line will output <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>.
This line is conventionally called a decision boundary.
This phenomenom means that the problem of predicting the output of an AND gate is <em>linearly separable</em>.
Meaning that we can separate the data into two classes using what is formally known as either a line or a hyperplane, put simply, it means we can construct a plane between the data points such that we can classify the points into two distinct classes.
In this trivial example we can easily find the hyperplane by hand, but for the sake of argument we will assume that we can not easily find this line (this is the case for more complex problems).</p>
<p>A <em>perceptron</em> is a mathematical function which is given a list of input values and it produces a single output. A perceptron computes the output by performing
a weighted sum between the input values and a list of randomly initialised weights and feeds the result through an activation function to obtain an output.
The activation function is responsible for determining whether the neuron should fire and is consequently usually a function that returns some value between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>.
Relating this back to the identified core tenet, the activation function can be thought of the decidor whether it <em>recognises</em> a piece of input.
Conceptually this means the AND gate will learn to only activate when <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">A = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>.
We will look at a special type of activation function that will always output either <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span> or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>, since these are the only valid output values for an AND gate.
Below we define the ‘architecture’ of the <em>perceptron</em> for predicting the output of an AND gate:</p>
<p><img src="/images/partOne/perceptronAnd.png" alt="Perceptron Architecure for And gate prediction"/>
<div align="center"><i>Figure 5: Perceptron Architecture</i></div></p>
<p>The perceptron has a special third input called the bias, we discuss the role of this component in the later sections.
The weights describe the state of a perceptron, they encode what the perceptron knows about the input data.
They are responsible for preparing the data before passing it to the activation function, which will make the final decision whether the perceptron should activate or not.
The weights are also useful in determining and assigning attention to the inputs by scaling the values in the weights to be closer to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span> or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>, so it is useful in doing automatic <em>feature engineering</em>, we’ll explore this topic a bit later in the series.</p>
<blockquote>
<p>Weights encode knowledge</p>
</blockquote>
<p>Our perceptron takes two inputs lablled A and B (gate inputs) and a third bias input, the weighted sum is calculated by performing the following operation:</p>
<div align="center"><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">(</mo><mi>A</mi><mo>×</mo><msub><mi>w</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mi>B</mi><mo>×</mo><msub><mi>w</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">S = (A \times w_1) + (B \times w_2) + b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span></p></div>
<p>This is then passed through to the activation function, the activation function will return <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span> if the weighted sum is positive and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span> if the weighted sum is less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.5</mn></mrow><annotation encoding="application/x-tex">0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.5</span></span></span></span>.</p>
<div align="center"><p>Activation Function: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">f(S) = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span> if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>&gt;</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">S &gt; 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.5</span></span></span></span> else <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span></p><div class="plot" data-astro-cid-6ryhialg> <iframe id="plotframe-/html/partOne/activation.html" src="/html/partOne/activation.html" width="100%" height="600px" style="border:none;" title="loss landscape" loading="lazy" class="plot-iframe" data-astro-cid-6ryhialg>
        Data
    </iframe>  </div>  <script>(function(){const htmlPath = "/html/partOne/activation.html";

    if (window !== null) {
        const button = document.getElementById("refreshButton-" + htmlPath);
        if (button) {
            button.addEventListener("click", () => {
                const iframe = document.getElementById("plotframe-"+htmlPath);
                iframe.contentWindow?.location.reload();
            });
        }
    }
  })();</script><i>Figure 6: Activation Function</i></div>
<p>We choose the value of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.5</mn></mrow><annotation encoding="application/x-tex">0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.5</span></span></span></span> arbitrarily as it lies in the middle of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>, which is the domain of the input variables. This type of function is commonly referred to as
a step function and is useful in our case for clamping the weighted sum to correspond to a valid AND gate output.</p>
<h3 id="training">Training</h3>
<hr/>
<p>Now how do we get the perceptron to actually emulate an AND gate? Well we need to train it.
To train our <em>perceptron</em> to correctly predict the output of an AND gate, we need to train it on some examples.
The possible inputs of the AND gate will be the examples which we will train our <em>perceptron</em> on(referred to as training data from here on).
As said by author John Bradsaw “mistakes are our teachers”, the perceptron has no perception of what an AND gate is, so we need to instill this knowledge into the model.</p>
<p>Since we know what the output of an AND gate should be, we can label the inputs of the traning data and ‘help’ the perceptron when it incorrectly predicts the output for a given set of data points.
We do this by calculating the difference between the output of the perceptron and the actual expected output.
This gives us an <em>error</em>, which we use to nudge the weights in a direction such that the output of the perceptron becomes closer to the expected output.
The value of the error is what we want to minimise.
To keep track of this error we will be using a more general loss function, mean-squared error, this will allow us to reason about error values that are positive.
We will formalise the loss function as follows:</p>
<div align="center"><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo stretchy="false">(</mo><mover accent="true"><mi>Y</mi><mo>^</mo></mover><mo>−</mo><mi>Y</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\mathcal{L}(\hat y, y) = \frac{1}{n}\sum_{i=1}^n(\hat Y - Y)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathcal">L</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1944em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2918em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span></span><span style="top:-3.2523em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></p><p><em>where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>Y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9468em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span></span><span style="top:-3.2523em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> is a list of actual outputs of the AND gate and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span></span></span></span> is a list of observed outputs from the perceptron</em></p></div>
<p>Now it would be useful if we could plot this loss function to get a better understanding of what our perceptron is trying to optimise.
Using the weights and all possible real numbered values in the range <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo>−</mo><mn>2</mn><mo separator="true">,</mo><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[-2,2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">−</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">2</span><span class="mclose">]</span></span></span></span> and the loss function definition we can calculate all possible error values for our input domain and plot them.
Plotting all of these points allows us to construct what is known as a loss landscape.</p>
<div class="plot" data-astro-cid-6ryhialg> <iframe id="plotframe-/html/partOne/loss_landscape.html" src="/html/partOne/loss_landscape.html" width="100%" height="600px" style="border:none;" title="loss landscape" loading="lazy" class="plot-iframe" data-astro-cid-6ryhialg>
        Data
    </iframe>  </div>  <script>(function(){const htmlPath = "/html/partOne/loss_landscape.html";

    if (window !== null) {
        const button = document.getElementById("refreshButton-" + htmlPath);
        if (button) {
            button.addEventListener("click", () => {
                const iframe = document.getElementById("plotframe-"+htmlPath);
                iframe.contentWindow?.location.reload();
            });
        }
    }
  })();</script>
<div align="center"><i>Figure 7: Loss Landscape(<a href="">Script</a>)</i></div>
<p>A loss landscape is a visual representation of the ‘terrain’ our perceptron will have to traverse to find the weight values that minimise the loss/error value.
The loss landscape is a valueable tool for gaining insight into model training dynamics. At a high-level we see a fairly flat landscape, which can make it difficult
for the model to learn, since changing the weights has no noticeable effect on the loss. The flat areas of the landscape are commonly referred to as flat minima.
The landscape also has high ridges, where there is a steep increase in loss, which make it difficult for the perceptron to move through. It is also extremely useful
in seeing the existince of optimal solutions, which in this case is where the loss is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span>. So if the weights are initialised between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">-2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">2</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2</span></span></span></span> we can see that there
is only one region of the landscape where the loss value is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span>.</p>
<p>With this in mind it should be clear to see that the initial value of the weights will impact how easy the perceptron will be able to find the optimal weight pair that minimises the loss function.
Consider our weight values are initialized such that the loss function output value is on the top <span style="color: #EEDC82;">yellow</span> plane. We will have to traverse multiple flat minima until we reach
the bottom of the ridges which will show improvement in the loss function value.
The loss landscape has given us the ‘answer’ to our perceptron learning problem, but quickly becomes infeasible to construct for more complicated problems as the number of weights is typically in the millions, so is typically only used for visualisation of simpler AI models.
This is however a nice guide, since we know what values we need to work towards for the weights of the perceptron. To train this perceptron we will define a simple algorithm:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8;overflow-x:auto" tabindex="0" data-language="text"><code><span class="line"><span>1. Initialize the weights randomly in the range [-2,2]</span></span>
<span class="line"><span>2. Iterate over each row in the possible </span></span>
<span class="line"><span>   inputs from AND gate table(Fig. 2)</span></span>
<span class="line"><span>3. Calculate the weighted sum: (A * w1) + (B * w2) + b</span></span>
<span class="line"><span>4. Apply activation function </span></span>
<span class="line"><span>5. Calculate difference between value from activation function </span></span>
<span class="line"><span>   and the actual expected AND gate output value: L = expected - predicted</span></span>
<span class="line"><span>6. Update weights according to difference: </span></span>
<span class="line"><span>    6.1 w1&#39; = w1 + learning_rate * error * A</span></span>
<span class="line"><span>    6.2 w2&#39; = w2 + learning_rate * error * B</span></span>
<span class="line"><span>    6.3 b&#39;  = b  + learning_rate * error</span></span>
<span class="line"><span>7. Repeat 2-6 some amount of times until satisfactory</span></span>
<span class="line"><span></span></span></code></pre>
<div align="center"><p><em>Algorithm 1: Perceptron Learning Algorithm</em></p></div>
<p>The perceptron learns by repeatedly trying to predict the AND gate output given an input sample.
It computes this output by performing a weighted sum. To better explicate what this weighted sum is doing we rewrite the
formula using an operation from linear algebra:</p>
<div align="center"><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">⟨</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">⟩</mo><mo>⋅</mo><mo stretchy="false">⟨</mo><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo stretchy="false">⟩</mo><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">S = \langle A, B \rangle \cdot \langle w_1, w_2 \rangle + b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">⟨</span><span class="mord mathnormal">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mclose">⟩</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">⟨</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">⟩</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span></p></div>
<p>The weighted sum is done by performing a dot product over the vector of the inputs (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle A, B \rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">⟨</span><span class="mord mathnormal">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mclose">⟩</span></span></span></span>) and the vector of the weights (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle w_1, w_2 \rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">⟨</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">⟩</span></span></span></span>).
A coordinate on an xy-graph is referred to as a 2-dimensional vector. Vectors can be n-dimensional, so the dimensionality of a vector depends on the number of values it contains.
The dot product can be visualised geometrically as follows:</p>
<div class="plot" data-astro-cid-6ryhialg> <iframe id="plotframe-/html/partOne/dot_product.html" src="/html/partOne/dot_product.html" width="100%" height="600px" style="border:none;" title="loss landscape" loading="lazy" class="plot-iframe" data-astro-cid-6ryhialg>
        Data
    </iframe>  </div>  <script>(function(){const htmlPath = "/html/partOne/dot_product.html";

    if (window !== null) {
        const button = document.getElementById("refreshButton-" + htmlPath);
        if (button) {
            button.addEventListener("click", () => {
                const iframe = document.getElementById("plotframe-"+htmlPath);
                iframe.contentWindow?.location.reload();
            });
        }
    }
  })();</script>
<div align="center"><i>Figure 8: Dot Product(<a href="">Script</a>)</i></div>
<p>A dot product between two vectors can be interpreted as a measure for how much of one vector lies in the direction of the other, in this case it is used to project the input vector to the weight vector in a sense.
The green line gives us an indication of this projection, but is not the actual answer to the dot product and is only used as a visual aid. Fundamentally the dot product measures
how much two vectors point in the same direction, so calculating this between the input and weight vectors tell us how much inputs relate to the weights of the perceptron. Put differently
it tells us how much the input data aligns with what the perceptron knows, since the weights encode the state of the knowledge of the perceptron.
The closer the input data is to what the perceptron knows the greater the chance for activation.
So when we give the perceptron a specific input all it is doing is translating those points using a simple projection. This is another important insight into how perceptrons work and will
become more clear when visualising more complex neural networks consisting of multiple of perceptrons.</p>
<blockquote>
<p>Perceptrons perform geometric transformations</p>
</blockquote>
<p>By updating the weights we are indirectly traversing the loss landscape, since the loss value dictates the direction in which the weights are updated.
You might have noticed a new variable <em>learning_rate</em>, the learning rate is usually a value between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span> and is used to
scale down the magnitude of the error value. The input values are included in the weight update to also help in scaling the weight value to be closer to the input, so that the magnitudes of the
weights still make sense.</p>
<p>To better understand the optimization step (6) in the algorithm, consider a sticky ball that we place on some random point on the loss landscape with a position corresponding to the values of the weights (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>), where the position of the ball
maps to the corresponding loss value of the perceptron. Since the ball is sticky and is also not affected by the slope of the landscape so it needs to be rolled to be able to move.
The direction we roll the ball in depends on the error and the amount of force we apply depends on the learning rate.
A higher learning rate can be detremental when training a perceptron or a neural network, if you apply a lot of force the ball might overshoot its target (Fig 5: Right), so generally learning rates are set to very
small numbers, but this is still problem depedent.</p>
<p><img src="/images/partOne/gradient.png" alt="Gradient"/>
<div align="center"><i>Figure 9: Ball Rolling Learning Analogy (<a href="https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.javatpoint.com%2Fgradient-descent-in-machine-learning&psig=AOvVaw3wUMJNd450L0Nt1atEeI73&ust=1729177462414000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCLDZ7JWWk4kDFQAAAAAdAAAAABAE">Credit</a>)</i></div></p>
<p>This analogy is the core idea behind the backpropagation algorithm, which is another revolutionary algorithm that allows us to efficiently train neural networks.
With this background, we can now look at an execution of our learning algorithm:</p>
<div class="plot" data-astro-cid-6ryhialg> <iframe id="plotframe-/html/partOne/loss_and.html" src="/html/partOne/loss_and.html" width="100%" height="600px" style="border:none;" title="loss landscape" loading="lazy" class="plot-iframe" data-astro-cid-6ryhialg>
        Data
    </iframe>  </div>  <script>(function(){const htmlPath = "/html/partOne/loss_and.html";

    if (window !== null) {
        const button = document.getElementById("refreshButton-" + htmlPath);
        if (button) {
            button.addEventListener("click", () => {
                const iframe = document.getElementById("plotframe-"+htmlPath);
                iframe.contentWindow?.location.reload();
            });
        }
    }
  })();</script>
<p>Here we see that our perceptron was able to successfully learn to emulate the AND gate after roughly 20 iterations(epochs).
Plotting the loss values over the epochs we can relate the loss values to the loss landscape from Figure xx.
For the first few iterations we see that the perceptron gets stuck in the flat minima regions of the loss landscape and it also struggles
with the ridges as it oscillates between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.25</mn></mrow><annotation encoding="application/x-tex">0.25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.25</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.5</mn></mrow><annotation encoding="application/x-tex">0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.5</span></span></span></span>, but luckily it seems to find a path from the flat minima to the global optimal solution.
To better understand these loss values let’s take a look at the values of the weights during the training process to see if we can plot the path through the loss landscape:</p>
<div class="plot" data-astro-cid-6ryhialg> <iframe id="plotframe-/html/partOne/weights_and.html" src="/html/partOne/weights_and.html" width="100%" height="600px" style="border:none;" title="loss landscape" loading="lazy" class="plot-iframe" data-astro-cid-6ryhialg>
        Data
    </iframe>  </div>  <script>(function(){const htmlPath = "/html/partOne/weights_and.html";

    if (window !== null) {
        const button = document.getElementById("refreshButton-" + htmlPath);
        if (button) {
            button.addEventListener("click", () => {
                const iframe = document.getElementById("plotframe-"+htmlPath);
                iframe.contentWindow?.location.reload();
            });
        }
    }
  })();</script>
<p>The final weights obtained are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">w_1 = 0.05</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.05</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub><mo>=</mo><mn>0.8</mn></mrow><annotation encoding="application/x-tex">w_2 = 0.8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.8</span></span></span></span>. With these weight values we can also plot a path through the loss landscape.</p>
<div class="plot" data-astro-cid-6ryhialg> <iframe id="plotframe-/html/partOne/loss_landscape_trace.html" src="/html/partOne/loss_landscape_trace.html" width="100%" height="600px" style="border:none;" title="loss landscape" loading="lazy" class="plot-iframe" data-astro-cid-6ryhialg>
        Data
    </iframe>  </div>  <script>(function(){const htmlPath = "/html/partOne/loss_landscape_trace.html";

    if (window !== null) {
        const button = document.getElementById("refreshButton-" + htmlPath);
        if (button) {
            button.addEventListener("click", () => {
                const iframe = document.getElementById("plotframe-"+htmlPath);
                iframe.contentWindow?.location.reload();
            });
        }
    }
  })();</script>
<p>Sampling the weight values from the loss function every four epochs, we trace these points on the loss landscape.
The perceptron was able to navigate the flat minima and followed the ridge line down into a lower flat minima (<span style="color: teal;">teal</span> plane).</p>
<p>Turning our attention back to Figure 3, we look at the decision boundary the perceptron found.
The decision boundary is a straight line, we need to find the equation of the line to draw it.
Looking at the weighted sum again we see something interesting:</p>
<div align="center"><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>A</mi><mo>×</mo><msub><mi>w</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mi>B</mi><mo>×</mo><msub><mi>w</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">(A \times w_1) + (B \times w_2) + b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span></p></div>
<p>This aligns with the standard form of a line():</p>
<div align="center"><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>x</mi><mo>+</mo><mi>B</mi><mi>y</mi><mo>=</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">Ax + By = C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span></p><p>Rewriting using perceptron variables:</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><msub><mi>w</mi><mn>1</mn></msub><mo>+</mo><mi>B</mi><msub><mi>w</mi><mn>2</mn></msub><mo>=</mo><mo>−</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Aw_1 + Bw_2 = -b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord mathnormal">b</span></span></span></span></p><p>Rewriting this in the more common slope-intercept(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>m</mi><mi>x</mi><mo>+</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">y = mx + c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">c</span></span></span></span>) form we get:</p><p>Solving for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub><mo>=</mo><mo>−</mo><mfrac><mi>A</mi><mi>B</mi></mfrac><msub><mi>w</mi><mn>1</mn></msub><mo>−</mo><mfrac><mi>b</mi><msub><mi>w</mi><mn>2</mn></msub></mfrac></mrow><annotation encoding="application/x-tex">w_2 = -\frac{A}{B}w_1 - \frac{b}{w_2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2173em;vertical-align:-0.345em"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.3252em;vertical-align:-0.4451em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em"><span style="top:-2.357em;margin-left:-0.0269em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p></div>
<p>With the slope-intercept equation in hand we can now substitute the variables we obtained after training the perceptron:</p>
<div align="center"><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mo>−</mo><mfrac><mi>A</mi><mi>B</mi></mfrac><mfrac><mn>0.05</mn><mn>0.8</mn></mfrac><mo>+</mo><mfrac><mn>0.3</mn><mn>0.8</mn></mfrac></mrow><annotation encoding="application/x-tex">y = -\frac{A}{B}\frac{0.05}{0.8} + \frac{0.3}{0.8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2173em;vertical-align:-0.345em"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0.8</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0.05</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0.8</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0.3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p></div>
<p>Finally we can plot the decision boundary:</p>
<div class="plot" data-astro-cid-6ryhialg> <iframe id="plotframe-/html/partOne/and_boundary.html" src="/html/partOne/and_boundary.html" width="100%" height="600px" style="border:none;" title="loss landscape" loading="lazy" class="plot-iframe" data-astro-cid-6ryhialg>
        Data
    </iframe>  </div>  <script>(function(){const htmlPath = "/html/partOne/and_boundary.html";

    if (window !== null) {
        const button = document.getElementById("refreshButton-" + htmlPath);
        if (button) {
            button.addEventListener("click", () => {
                const iframe = document.getElementById("plotframe-"+htmlPath);
                iframe.contentWindow?.location.reload();
            });
        }
    }
  })();</script>
<p>The perceptron actually found a more optimal decision boundary than the one we drew by hand in Figure 3.</p>
<h3 id="whats-next">What’s Next?</h3>
<hr/>
<p>Our perceptron was able to easily learn to emulate an AND gate, but what about an XOR gate? An XOR gate or exclusive or gate, is a circuit that is energized when exactly only one of its inputs are energized.</p>
<div align="center"><p><img src="/images/partOne/xor.png" alt="XOR Gate"/></p></div>
<div align="center"><i>Fig 6: XOR Gate (<a href="https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.build-electronic-circuits.com%2Fxor-gate%2F&psig=AOvVaw0-514KxhLrsRZLPJKxj-Jt&ust=1729190950216000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCMiU_7TIk4kDFQAAAAAdAAAAABAE">Credit</a>)</i></div>
<p>Plotting the possible input values and their corresponding activations, we get the following:</p>
<div class="plot" data-astro-cid-6ryhialg> <iframe id="plotframe-/html/partOne/xor.html" src="/html/partOne/xor.html" width="100%" height="600px" style="border:none;" title="loss landscape" loading="lazy" class="plot-iframe" data-astro-cid-6ryhialg>
        Data
    </iframe>  </div>  <script>(function(){const htmlPath = "/html/partOne/xor.html";

    if (window !== null) {
        const button = document.getElementById("refreshButton-" + htmlPath);
        if (button) {
            button.addEventListener("click", () => {
                const iframe = document.getElementById("plotframe-"+htmlPath);
                iframe.contentWindow?.location.reload();
            });
        }
    }
  })();</script>
<p>Here we see that we can not separate the points with a straight hyperplane, but rather with a complex curve. To find this hyperplane we will need a more complex transformation, which is not something
that a perceptron can do on its own, but with the help of other perceptrons we can make this a reality. To be continued in Part II…</p>
<div class="done-container" data-astro-cid-nip4t23h> <h2 class="mesh-text" data-astro-cid-nip4t23h>Thank you for reading!</h2> <span class="star" data-astro-cid-nip4t23h></span> <span class="star" data-astro-cid-nip4t23h></span> <span class="star" data-astro-cid-nip4t23h></span> </div>   </div> </article> </main> <footer data-astro-cid-sz7xmlte> <div class="tag-line" data-astro-cid-sz7xmlte> <div class="logo-container" data-astro-cid-sz7xmlte> <div class="mesh-logo"> <svg width="60" height="60" viewBox="0 0 1272 1197" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M908.083 598.043L878.363 609.55L867.354 638.955L925.205 697.066L751.853 871.199L677.105 796.114L735.278 737.679C740.223 741.199 746.038 742.971 751.853 742.971C759.233 742.971 766.589 740.15 772.23 734.484L867.354 638.93L861.813 622.605L826.626 598.018L751.878 673.103L675.639 596.52L636.376 638.93L602.829 590.779L520.875 673.103L441.654 593.525L405.398 638.93L500.523 734.484C506.139 740.125 513.519 742.971 520.9 742.971C526.715 742.971 532.505 741.174 537.475 737.679L595.648 796.114L520.9 871.199L347.523 697.066L405.373 638.955L371.851 590.779L286.443 676.623C275.186 687.93 275.186 706.252 286.443 717.535L500.523 932.58C506.139 938.222 513.519 941.067 520.9 941.067C528.28 941.067 535.636 938.247 541.277 932.58L636.401 837.027L731.526 932.58C737.142 938.222 744.522 941.067 751.903 941.067C759.283 941.067 766.639 938.247 772.279 932.58L986.36 717.535C997.617 706.227 997.617 687.905 986.36 676.623L908.133 598.043H908.083ZM578.501 697.091L636.352 638.98L694.202 697.091L636.352 755.202L578.501 697.091Z" fill="#403B65"></path> <path d="M347.523 498.995L520.9 324.862L595.648 399.947L536.133 459.73C537.45 460.679 538.742 461.702 539.935 462.9L577.184 500.318L636.376 440.859L696.513 501.266L733.762 463.849C734.955 462.65 736.223 461.627 737.564 460.678L677.13 399.972L751.878 324.887L925.229 499.02L867.379 557.131L880.848 583.191L908.108 598.068L986.335 519.488C997.592 508.181 997.592 489.859 986.335 478.576L772.205 263.481C760.948 252.173 742.708 252.173 731.476 263.481L636.352 359.034L541.252 263.481C529.995 252.173 511.755 252.173 500.523 263.481L286.443 478.551C275.186 489.859 275.186 508.181 286.443 519.463L364.67 598.043L409.797 561.549L347.548 499.02L347.523 498.995Z" fill="#403B65"></path> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M446.104 598.032L405.374 638.947L429.675 663.357L470.406 622.443L446.104 598.032Z" fill="#403B65"></path> </g> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M660.58 663.293L701.309 622.356L679.043 599.99L677.055 598.043L636.376 638.98L637.147 639.779L660.58 663.293Z" fill="#403B65"></path> </g> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M537.449 737.704L562.1 762.441L602.829 721.529L578.501 697.091L537.449 737.704Z" fill="#403B65"></path> </g> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M677.104 796.137L636.374 837.051L660.71 861.497L701.44 820.583L677.104 796.137Z" fill="#403B65"></path> </g> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M677.082 399.957L636.351 440.871L660.67 465.3L701.4 424.386L677.082 399.957Z" fill="#403B65"></path> </g> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M826.608 598.042L802.289 622.47L843.02 663.385L867.338 638.956L826.608 598.042Z" fill="#403B65"></path> </g> <g style="mix-blend-mode:multiply" opacity="0.7"> <path d="M694.226 697.091L669.898 721.529L710.627 762.441L735.278 737.704L694.226 697.091Z" fill="#403B65"></path> </g> <path d="M772.205 461.552C762.141 451.443 746.51 450.419 735.278 458.382C733.961 459.331 732.669 460.354 731.476 461.552L636.351 557.131L541.227 461.552C540.034 460.354 538.766 459.331 537.425 458.382C526.193 450.419 510.537 451.443 500.498 461.552L364.645 598.018L405.373 638.93L520.85 522.933L636.326 638.955L751.803 522.908L867.28 638.93L908.008 598.018L772.155 461.552H772.205Z" fill="url(#paint0_linear_2_21)"></path> <defs> <linearGradient id="paint0_linear_2_21" x1="842.679" y1="679.293" x2="605.797" y2="559.24" gradientUnits="userSpaceOnUse"> <stop offset="0.16" stop-color="#403B65"></stop> <stop offset="1" stop-color="#DC0451"></stop> </linearGradient> </defs> </svg> </div> </div> <p data-astro-cid-sz7xmlte>
&copy; 2024 <span class="mesh-text" data-astro-cid-sz7xmlte>Mesh.Trade</span>. All rights reserved.
</p> </div> <div class="social-links" data-astro-cid-sz7xmlte> <a href="https://github.com/meshtrade/mesh-dev-blog" target="_new" data-astro-cid-sz7xmlte> <span class="sr-only" data-astro-cid-sz7xmlte>Go to the github repo</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" astro-icon="social/github" data-astro-cid-sz7xmlte><path fill="currentColor" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" data-astro-cid-sz7xmlte></path></svg> </a> </div> </footer>  <script>(function(){const title = "AI Visualised - Part I";

		const scroll = document.getElementById(title) ?? new HTMLElement();

		window.onscroll = () => {
			if (document.documentElement.scrollTop <= 500) {
				scroll.style.display = "none";
				return;
			} 
			scroll.style.display = "block";
		};

		scroll?.addEventListener("click", e => {
			document.documentElement.scrollTo({
				behavior: "smooth",
				top: 0,
			});
		});
	})();</script> </body></html>